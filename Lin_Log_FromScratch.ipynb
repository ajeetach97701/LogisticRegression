{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression From Scratch\n",
    "- step 1: initialize learning rate(lr) number of iterations(n_iters)(epochs), weights and bias \n",
    "- step 2: Fit Function:\n",
    "    - extract number of rows and number of columns from the given training data passed to fit function.\n",
    "    - weights -> 0 , bias -> 0\n",
    "    - initialize y_hat = wx + b\n",
    "    - loop to update the value of weights and bias using the formula\n",
    "        - dw = (1/n) ∑(y - y_hat) * X\n",
    "        - db = (1/n) ∑(y - y_hat)\n",
    "        - weight(new) = weight(old) + lr * dw\n",
    "        - bias(new) = bias(old) + lr * db\n",
    "\n",
    "- step 3: Predict Funciton: \n",
    "    - y_hat  = WX + b and return y_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self,lr, n_iters):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.n_iters):\n",
    "            y_hat = np.dot(X, self.weights) + self.bias\n",
    "            dw = 1/(n_samples) * np.dot(X.T, (y-y_hat))\n",
    "            db = 1/(n_samples) * np.sum(y-y_hat)\n",
    "            \n",
    "            self.weights = self.weights - self.lr * dw\n",
    "            self.bias = self.bias - self.lr * db\n",
    "            \n",
    "    def predict(self, X):\n",
    "        y_hat = np.dot(X, self.weights) + self.bias\n",
    "        return y_hat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression From Scratch\n",
    "- step 1: initialize learning rate(lr) number of iterations(n_iters)(epochs), weights and bias \n",
    "- step 2: Fit Function:\n",
    "    - extract number of rows and number of columns from the given training data passed to fit function.\n",
    "    - weights -> 0 , bias -> 0\n",
    "    - initialize y_hat = wx + b and pass the obtained output to sigmoid function\n",
    "        - sigmoid function: \n",
    "            - S(x)= 1/ 1+e^(-x)\n",
    "\n",
    "    - loop to update the value of weights and bias using the formula\n",
    "        - dw = (1/n) ∑(y - y_hat) * X\n",
    "        - db = (1/n) ∑(y - y_hat)\n",
    "        - weight(new) = weight(old) + lr * dw\n",
    "        - biad(new) = bias(old) + lr * db\n",
    "\n",
    "- step 3: Predict Funciton: \n",
    "    - prediction = WX + b and pass the obtained output to sigmoid function. Return 0 if the output of sigmoid function is <= 0.5 and 1 if > 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr, n_iters = 1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.n_iters):\n",
    "            pred = np.dot(X, self.weights) + self.bias\n",
    "            y_hat = sigmoid(pred)\n",
    "            \n",
    "            dw = 1/(n_samples) * np.dot((y - y_hat), X)\n",
    "            db = 1/(n_samples) * np.sum(y - y_hat)\n",
    "            \n",
    "            self.weights = self.weights + self.lr * dw\n",
    "            self.bias = self.bias + self.lr * db\n",
    "            \n",
    "    def predict(self, X):\n",
    "        pred  = np.dot(X, self.weights) + self.bias\n",
    "        y_hat = sigmoid(pred)\n",
    "        prediction = [0 if y<= 0.5 else 1 for y in y_hat]\n",
    "        return prediction\n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
